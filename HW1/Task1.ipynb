{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#import sklearn\n",
    "import string\n",
    "import pickle\t# this is for saving and loading your trained classifiers.\n",
    "import re \n",
    "from sklearn.svm import SVC\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.stem import  WordNetLemmatizer\n",
    "import contractions\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import words\n",
    "from nltk import NaiveBayesClassifier, ConfusionMatrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\t#filename is of type string. example call: preprocess(\"philosophy_test.txt\")\t\n",
    "\n",
    "\tfilepath = filename\t\t\t\t\t# you might need to change filepath depending where do you store your data files.\n",
    "\tfile = open(filepath, 'r', encoding='utf-8')\t\t\t# 'r' for read\n",
    "\tlines = file.read().splitlines()\t# lines is a list holding each line of your file as strings. e.g. lines = [\"This is the 1st line of the file\", \"This is the 2nd line of the file\", ...]\n",
    "\tfile.close()\n",
    "\n",
    "\tprocessed = []\t\t# fill this list with the preprocessed form of the text in the file. you may change to another data structure, if you need. \n",
    "\t\t\t\t\t\t# do not forget to label your documents. \n",
    "\t\t\t\t\t\t# if a document from Class1 becomes \"world case speak silent\" after basic text processing steps; after labeling, it will look like (\"world case speak silent\", Class1)\n",
    "\tgenre = filename.split(\"/\")[3].split(\"_\")[0]\n",
    " \n",
    "\tlen_doc = len(lines)\n",
    "\tlemmatizer = WordNetLemmatizer()\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\tenglish_words_set = set(words.words())\n",
    "\tfor i in range(0, len_doc, 2):\n",
    "     \n",
    "\t\t#-----------------------------remove punctuation-----------------------\n",
    "\t\tlines[i] = re.sub(r'[\\(\\)\\.\\:\\!\\?\\;\\,\\.\\€\\-\\\"\\Ã\\¦\\•\\â\\Â\\”]', ' ',lines[i])\n",
    "\t\tlines[i+1] = re.sub(r'[\\(\\)\\.\\:\\!\\?\\;\\,\\.\\€\\-\\\"\\Ã\\¦\\•\\â\\Â\\”]', ' ',lines[i+1])\n",
    "\t\t\n",
    "  \t\t#-----------------------------tokenize---------------------------------\n",
    "\t\topened_title = contractions.fix(lines[i]) # he's -> he is\n",
    "\t\ttokened_title = opened_title.split()\n",
    "\t\ttokened_title = [word.lower() for word in tokened_title if word.isalnum() and (word.lower() not in stop_words) and (word[0].isupper() or (word.lower() in english_words_set) ) ]\n",
    "\t\t\n",
    "\t\topened_description = contractions.fix(lines[i+1]) # he's -> he is\n",
    "\t\ttokened_description = opened_description.split()\n",
    "\t\ttokened_description = [word.lower() for word in tokened_description if word.isalnum() and (word.lower() not in stop_words) and (word[0].isupper() or (word.lower() in english_words_set) ) ]\n",
    "\n",
    "\t\t#----------------------------- lemmatization---------------------------------\n",
    "\t\tfor word in tokened_title:\n",
    "\t\t\tword = lemmatizer.lemmatize(word)\n",
    "\t\tfor word in tokened_description:\n",
    "\t\t\tword = lemmatizer.lemmatize(word)\n",
    "\t\t\n",
    "\t\t#-----------------------------bag of words---------------------------------\n",
    "\t\tpreprocessed_title = \" \".join(tokened_title)\n",
    "\t\tpreprocessed_descr = \" \".join(tokened_description)\n",
    "\t\tprocessed.append((preprocessed_title + \" \" + preprocessed_title + \" \" + \" \" + preprocessed_descr, genre)) \n",
    "\n",
    "\treturn processed \t# you may change the return value if you need.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "def create_megadoc(type):\n",
    "\tdocuments = [f\"philosophy_{type}.txt\",f\"sports_{type}.txt\",f\"mystery_{type}.txt\",f\"religion_{type}.txt\",f\"science_{type}.txt\",f\"romance_{type}.txt\",f\"horror_{type}.txt\",f\"science-fiction_{type}.txt\"]\n",
    "\tmegadoc = []\n",
    "\tbasedir = f\"./data/{type}/\"\n",
    "\n",
    "\tgenre_based_words_dict = dict()\n",
    "\tfor filename in documents:\n",
    "\t\tsentences_for_curr_genre = preprocess(basedir + filename)\n",
    "\t\tmegadoc += sentences_for_curr_genre\n",
    "\t\tall_sentences, genres = zip(*sentences_for_curr_genre)\n",
    "\t\tgenre_based_words_dict[filename.split(\"_\")[0]] = all_sentences\n",
    "  \n",
    "\treturn megadoc, genre_based_words_dict\n",
    "\t\n",
    "####################################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_train, y_train, genre_based_words_dict):    \n",
    "    # ------------------ TF-IDF + chi square ------------------\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=9000)  \n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    chi2_result = chi2(X_train_tfidf, y_train)\n",
    "    selected_feature_indices = np.argsort(chi2_result[0])[::-1]\n",
    "    top_n_features = 1200\n",
    "    selected_features = set([tfidf_vectorizer.get_feature_names_out()[i] for i in selected_feature_indices[:top_n_features]])\n",
    "    \n",
    "    \n",
    "    # ------------------ FreqDist ------------------ did not work well\n",
    "    # frequently_used_words = set()\n",
    "    # for genre, sentences in genre_based_words_dict.items():\n",
    "    #     all_words = [word for word in \" \".join(sentences).split()]\n",
    "    #     fdist = FreqDist(all_words)\n",
    "    #     top_n_words = set([w for w, c in fdist.most_common(500)])\n",
    "    #     frequently_used_words = frequently_used_words.union(top_n_words)\n",
    "        \n",
    "    # selected_features = set(selected_features).union(frequently_used_words)\n",
    "    \n",
    "    # # ------------------ Anova ------------------ did not work well\n",
    "    # anova_f = SelectKBest(f_classif, k=600)  \n",
    "    # anova_f_train = anova_f.fit_transform(X_train_tfidf, y_train)\n",
    "\n",
    "    # selected_feature_indices = anova_f.get_support(indices=True)\n",
    "    # feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # # Get the selected words\n",
    "    # anova_selected_words = set([feature_names[i] for i in selected_feature_indices])\n",
    "    # selected_features = selected_features.union(anova_selected_words)\n",
    "    eliminate_this = {'ice','dr', 'ever','art','ex','ty','eve', 'one', 'us','de', 'thing', 'age', 'han', 'old','young','get'} #these words are obtained from development set\n",
    "    selected_features = selected_features.difference(eliminate_this)\n",
    "    \n",
    "    return list(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X_sth, y_sth, selected_features):\t\t# megadoc can be either training_megadoc for training phase or test_megadoc for testing phase.\n",
    "\textracted_features = list()\n",
    "\tx_and_y = list(zip(X_sth, y_sth))\n",
    "\tfor sentence, genre in x_and_y:\n",
    "\t\tcurr_sent_features = dict()\n",
    "\t\tfor feature in selected_features:\n",
    "\t\t\tcurr_sent_features[feature] = feature in sentence\n",
    "\t\textracted_features.append((curr_sent_features,genre))\n",
    "\n",
    "\treturn extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_classifier(classifier, filename):\t#filename should end with .pickle and type(filename)=string\n",
    "\twith open(filename, \"wb\") as f:\n",
    "\t\tpickle.dump(classifier, f)\n",
    "\treturn\n",
    "\t\n",
    "\t\n",
    "def load_classifier(filename):\t#filename should end with .pickle and type(filename)=string\n",
    "\tclassifier_file = open(filename, \"rb\")\n",
    "\tclassifier = pickle.load(classifier_file)\n",
    "\tclassifier_file.close()\n",
    "\treturn classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, train_features):\t# classifier is either nltk.NaiveBayesClassifier or SklearnClassifier(SVC()). Example call: train(SklearnClassifier(SVC()), training_set)\n",
    "\treturn classifier.train(train_features)\n",
    "\n",
    "\t\n",
    "def test(classifier, test_features):\t# classifier is either nltk.NaiveBayesClassifier or SklearnClassifier(SVC()). Example call: test(SklearnClassifier(SVC()), test_set)\n",
    "\tfeatures_dict, genres = zip(*test_features)\n",
    "\ty_pred = classifier.classify_many(features_dict)\n",
    "\tgenres = list(genres)\n",
    "\ty_pred = list(y_pred)\n",
    "\tconfusion_matrix = ConfusionMatrix(genres,y_pred)\n",
    "\taccuracy = nltk.scores.accuracy(genres, y_pred)\n",
    "\tprint(f\"Accuracy: {accuracy}\")\n",
    "\treturn confusion_matrix\n",
    "\n",
    "def examine_confusion(confusion_matrix):\n",
    "\tprint(confusion_matrix.pretty_format(sort_by_count=True))\n",
    "\tprint(confusion_matrix.evaluate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------main--------------\n",
    "train_megadoc, genre_based_words_dict_train = create_megadoc(\"train\")\n",
    "X_train, y_train = zip(*train_megadoc)\n",
    "dev_megadoc, genre_based_words_dict_dev = create_megadoc(\"dev\")\n",
    "X_dev, y_dev = zip(*dev_megadoc)\n",
    "test_megadoc, genre_based_words_dict_test = create_megadoc(\"test\")\n",
    "X_test, y_test = zip(*test_megadoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size train:  6536\n",
      "size dev:  933\n",
      "size test:  1865\n"
     ]
    }
   ],
   "source": [
    "print(\"size train: \", len(train_megadoc))\n",
    "print(\"size dev: \", len(dev_megadoc))\n",
    "print(\"size test: \", len(test_megadoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('republic republic  presented form dialogue socrates three different classic text enquiry notion perfect community ideal individual within conversation raised goodness reality knowledge republic also purpose education role men people remarkable lucidity deft use allegory plato depiction state bound harmony philosopher',\n",
       " 'philosophy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_megadoc[0] #example of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fatures = feature_selection(X_train, y_train, genre_based_words_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_fatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(X_train, y_train, selected_fatures)\n",
    "dev_features = extract_features(X_dev,y_dev, selected_fatures)\n",
    "test_features = extract_features(X_test, y_test, selected_fatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7341907824222936\n",
      "                |     s                   |\n",
      "                |     c                   |\n",
      "                |     i                   |\n",
      "                |     e                   |\n",
      "                |     n                   |\n",
      "                |     c              p    |\n",
      "                |     e              h    |\n",
      "                |     -        r     i    |\n",
      "                |  m  f        e  s  l  r |\n",
      "                |  y  i  h  s  l  c  o  o |\n",
      "                |  s  c  o  p  i  i  s  m |\n",
      "                |  t  t  r  o  g  e  o  a |\n",
      "                |  e  i  r  r  i  n  p  n |\n",
      "                |  r  o  o  t  o  c  h  c |\n",
      "                |  y  n  r  s  n  e  y  e |\n",
      "----------------+-------------------------+\n",
      "        mystery |<91> 3 14  1  .  .  . 11 |\n",
      "science-fiction |  4<85>19  2  1  2  .  7 |\n",
      "         horror | 14  8<82> 1  .  .  1 12 |\n",
      "         sports |  .  .  1<99> 1  .  . 16 |\n",
      "       religion |  2  5  6  .<78> 3 18  3 |\n",
      "        science |  2 14  8  .  2<85> 4  . |\n",
      "     philosophy |  1  3  3  . 12 14<80> 1 |\n",
      "        romance |  3  9  9  6  1  .  1<85>|\n",
      "----------------+-------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "            Tag | Prec.  | Recall | F-measure\n",
      "----------------+--------+--------+-----------\n",
      "         horror | 0.5775 | 0.6949 | 0.6308\n",
      "        mystery | 0.7778 | 0.7583 | 0.7679\n",
      "     philosophy | 0.7692 | 0.7018 | 0.7339\n",
      "       religion | 0.8211 | 0.6783 | 0.7429\n",
      "        romance | 0.6296 | 0.7456 | 0.6827\n",
      "        science | 0.8173 | 0.7391 | 0.7763\n",
      "science-fiction | 0.6693 | 0.7083 | 0.6883\n",
      "         sports | 0.9083 | 0.8462 | 0.8761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbc_classifier = train(NaiveBayesClassifier,train_features)\n",
    "\n",
    "save_classifier(nbc_classifier, \"naive_bayes.pickle\")\n",
    "\n",
    "nbc_confusion_matrix = test(nbc_classifier,dev_features)\n",
    "\n",
    "examine_confusion(nbc_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7190348525469169\n",
      "                |       s                         |\n",
      "                |       c                         |\n",
      "                |       i                         |\n",
      "                |       e                         |\n",
      "                |       n                         |\n",
      "                |       c                   p     |\n",
      "                |       e                   h     |\n",
      "                |       -           r       i     |\n",
      "                |   m   f           e   s   l   r |\n",
      "                |   y   i   s   h   l   c   o   o |\n",
      "                |   s   c   p   o   i   i   s   m |\n",
      "                |   t   t   o   r   g   e   o   a |\n",
      "                |   e   i   r   r   i   n   p   n |\n",
      "                |   r   o   t   o   o   c   h   c |\n",
      "                |   y   n   s   r   n   e   y   e |\n",
      "----------------+---------------------------------+\n",
      "        mystery |<178>  6   .  36   3   2   .  15 |\n",
      "science-fiction |   9<153>  .  45   3   8   4  18 |\n",
      "         sports |   1   5<181>  7   .   2   .  39 |\n",
      "         horror |  19  23   1<176>  3   .   .  12 |\n",
      "       religion |   3   9   1  14<150> 10  39   4 |\n",
      "        science |   3  20   1   9   2<173> 21   1 |\n",
      "     philosophy |   .   6   2   3  17  27<172>  1 |\n",
      "        romance |   8  19  18  24   1   .   .<158>|\n",
      "----------------+---------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "            Tag | Prec.  | Recall | F-measure\n",
      "----------------+--------+--------+-----------\n",
      "         horror | 0.5605 | 0.7521 | 0.6423\n",
      "        mystery | 0.8054 | 0.7417 | 0.7722\n",
      "     philosophy | 0.7288 | 0.7544 | 0.7414\n",
      "       religion | 0.8380 | 0.6522 | 0.7335\n",
      "        romance | 0.6371 | 0.6930 | 0.6639\n",
      "        science | 0.7793 | 0.7522 | 0.7655\n",
      "science-fiction | 0.6349 | 0.6375 | 0.6362\n",
      "         sports | 0.8873 | 0.7702 | 0.8246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbc_test_cm = test(nbc_classifier,test_features)\n",
    "examine_confusion(nbc_test_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test features examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict, genres = zip(*test_features)\n",
    "size_genres = len(genres)\n",
    "horror_dict = dict()\n",
    "mys_dict = dict()\n",
    "philosophy_dict = dict()\n",
    "for i in range(size_genres):\n",
    "    if genres[i] == \"horror\":\n",
    "        curr_dict = features_dict[i]\n",
    "        for key in curr_dict.keys():\n",
    "            if curr_dict[key] == True:\n",
    "                if key in horror_dict.keys():\n",
    "                    horror_dict[key] += 1\n",
    "                else:\n",
    "                    horror_dict[key] = 1\n",
    "                    \n",
    "    if genres[i] == \"mystery\":\n",
    "        curr_dict = features_dict[i]\n",
    "        for key in curr_dict.keys():\n",
    "            if curr_dict[key] == True:\n",
    "                if key in mys_dict.keys():\n",
    "                    mys_dict[key] += 1\n",
    "                else:\n",
    "                    mys_dict[key] = 1\n",
    "                    \n",
    "    if genres[i] == \"philosophy\":\n",
    "        curr_dict = features_dict[i]\n",
    "        for key in curr_dict.keys():\n",
    "            if curr_dict[key] == True:\n",
    "                if key in philosophy_dict.keys():\n",
    "                    philosophy_dict[key] += 1\n",
    "                else:\n",
    "                    philosophy_dict[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict_mys = sorted(mys_dict.items(), key=lambda x: x[1])\n",
    "sorted_dict_horro = sorted(horror_dict.items(), key=lambda x: x[1])\n",
    "sorted_dict_philo = sorted(philosophy_dict.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('found', 57), ('ring', 59), ('win', 60), ('death', 61), ('dead', 64), ('life', 64), ('king', 67), ('kill', 68), ('murder', 73), ('pro', 74)]\n"
     ]
    }
   ],
   "source": [
    "print(list(sorted_dict_mys[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ali', 53), ('dead', 54), ('pro', 56), ('night', 56), ('evil', 57), ('life', 59), ('dark', 60), ('war', 60), ('world', 63), ('king', 71)]\n"
     ]
    }
   ],
   "source": [
    "print(list(sorted_dict_horro[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('king', 61), ('vol', 62), ('life', 75), ('world', 76), ('philosophy', 82), ('du', 95), ('ali', 97), ('book', 97), ('work', 102), ('pro', 112)]\n"
     ]
    }
   ],
   "source": [
    "print(list(sorted_dict_philo[-10:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7063236870310825\n",
      "                |     s                   |\n",
      "                |     c                   |\n",
      "                |     i                   |\n",
      "                |     e                   |\n",
      "                |     n                   |\n",
      "                |     c              p    |\n",
      "                |     e              h    |\n",
      "                |     -        r     i    |\n",
      "                |  m  f        e  s  l  r |\n",
      "                |  y  i  h  s  l  c  o  o |\n",
      "                |  s  c  o  p  i  i  s  m |\n",
      "                |  t  t  r  o  g  e  o  a |\n",
      "                |  e  i  r  r  i  n  p  n |\n",
      "                |  r  o  o  t  o  c  h  c |\n",
      "                |  y  n  r  s  n  e  y  e |\n",
      "----------------+-------------------------+\n",
      "        mystery |<86> 6 16  1  .  .  . 11 |\n",
      "science-fiction |  7<85>17  1  1  2  .  7 |\n",
      "         horror | 15 16<73> 3  1  .  2  8 |\n",
      "         sports |  .  .  1<99> 1  .  1 15 |\n",
      "       religion |  2  4  4  .<81> 6 14  4 |\n",
      "        science |  . 11  4  2  5<88> 4  1 |\n",
      "     philosophy |  2  4  2  . 20 14<72> . |\n",
      "        romance |  5 14  8  8  2  .  2<75>|\n",
      "----------------+-------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "            Tag | Prec.  | Recall | F-measure\n",
      "----------------+--------+--------+-----------\n",
      "         horror | 0.5840 | 0.6186 | 0.6008\n",
      "        mystery | 0.7350 | 0.7167 | 0.7257\n",
      "     philosophy | 0.7579 | 0.6316 | 0.6890\n",
      "       religion | 0.7297 | 0.7043 | 0.7168\n",
      "        romance | 0.6198 | 0.6579 | 0.6383\n",
      "        science | 0.8000 | 0.7652 | 0.7822\n",
      "science-fiction | 0.6071 | 0.7083 | 0.6538\n",
      "         sports | 0.8684 | 0.8462 | 0.8571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_classifier = train(SklearnClassifier(SVC(kernel='rbf')),train_features)\n",
    "save_classifier(svc_classifier, \"svc_classifier.pickle\")\n",
    "svc_confusion_matrix = test(svc_classifier,dev_features)\n",
    "examine_confusion(svc_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7045576407506703\n",
      "                |       s                         |\n",
      "                |       c                         |\n",
      "                |       i                         |\n",
      "                |       e                         |\n",
      "                |       n                         |\n",
      "                |       c                   p     |\n",
      "                |       e                   h     |\n",
      "                |       -           r       i     |\n",
      "                |   m   f           e   s   l   r |\n",
      "                |   y   i   s   h   l   c   o   o |\n",
      "                |   s   c   p   o   i   i   s   m |\n",
      "                |   t   t   o   r   g   e   o   a |\n",
      "                |   e   i   r   r   i   n   p   n |\n",
      "                |   r   o   t   o   o   c   h   c |\n",
      "                |   y   n   s   r   n   e   y   e |\n",
      "----------------+---------------------------------+\n",
      "        mystery |<174> 11   3  33   4   1   .  14 |\n",
      "science-fiction |  11<157>  .  41   3   6   4  18 |\n",
      "         sports |   1   5<184>  4   1   3   1  36 |\n",
      "         horror |  28  28   1<160>  4   1   .  12 |\n",
      "       religion |   4  10   .   8<157> 12  31   8 |\n",
      "        science |   2  17   3   5   9<170> 23   1 |\n",
      "     philosophy |   1   9   .   1  31  31<154>  1 |\n",
      "        romance |   7  20  19  24   .   .   .<158>|\n",
      "----------------+---------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "            Tag | Prec.  | Recall | F-measure\n",
      "----------------+--------+--------+-----------\n",
      "         horror | 0.5797 | 0.6838 | 0.6275\n",
      "        mystery | 0.7632 | 0.7250 | 0.7436\n",
      "     philosophy | 0.7230 | 0.6754 | 0.6984\n",
      "       religion | 0.7512 | 0.6826 | 0.7153\n",
      "        romance | 0.6371 | 0.6930 | 0.6639\n",
      "        science | 0.7589 | 0.7391 | 0.7489\n",
      "science-fiction | 0.6109 | 0.6542 | 0.6318\n",
      "         sports | 0.8762 | 0.7830 | 0.8270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_confusion_matrix_test = test(svc_classifier,test_features)\n",
    "examine_confusion(svc_confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
